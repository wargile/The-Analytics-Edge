---
title: "The Analytics Edge (Unit 3)"
author: "Na Sai"
date: "March 26, 2015"
output: html_document

In this unit we introduce three new packages: CaTools package is used to randomly split datasets into training and testing sets using the "sample.split" function. For assignment,  use set.seed(88) to initialize the same random generator. The ROCR package is used for visualizing binary classifier performance. ROC stands for "Receiver Operating Chracteristic". The MICE package is used for multiple imputation for filling missing data. 

---
# Lecture
## Modeling the Expert: an Intro to Logistic Regression 
```{r}
b0 = -1.5;b1 = 3; b2 = -0.5
logit <- function(x1,x2){return(b0+b1*x1+b2*x2)}
odd <- function(x1,x2){return(exp(b0+b1*x1+b2*x2))}
P <- function(x1,x2){return(1/(1+exp(-(b0+b1*x1+b2*x2))))}
logit(1,5)
odd(1,5)
P(1,5)
```
In R, create a logistic regression model to predict "PoorCare" using the independent variables "StartedOnCombination" and "ProviderCount".

```{r}
quality <- read.csv("quality.csv")
str(quality)
install.packages("caTools",dependencies = T, repos="http://cran.rstudio.com/")
require(caTools)
set.seed(88)
split <- sample.split(quality$PoorCare,SplitRatio=0.75)
qualityTrain<-subset(quality,split==TRUE)
qualityTest<-subset(quality,split==FALSE)
quality.glm <- glm(PoorCare ~ StartedOnCombination + ProviderCount, data = qualityTrain, family = binomial)
summary(quality.glm)
```

This question asks about the following two confusion matrices:
```{r}
TP = 20; FN = 5 
sensitivity = TP / (TP + FN)
sensitivity
TN = 15;FP = 10
specifity = TN / (TN + FP)
specifity
# from confusion matrix#1 to matrix #2, TP decreases, TN increase; sensitivity decreases; specificity increases  
```
This question uses the original model with the independent variables "OfficeVisits" and "Narcotics".
```{r}
quality.glm.ori <- glm(PoorCare ~ OfficeVisits + Narcotics, data = qualityTrain, family = binomial)
summary(quality.glm.ori)
# Compute the test set predictions
predictTest <- predict(quality.glm.ori, type = "response", newdata = qualityTest)
# install and load the ROCR package
install.packages("ROCR",dependencies = T, repos="http://cran.rstudio.com/")
require(ROCR)
ROCRpredTest <- prediction(predictTest,qualityTest$PoorCare)
auc = as.numeric(performance(ROCRpredTest,"auc")@y.values)
auc
```
## The Framinham Heart Study: Evaluating Risk Factors to Save Lives. 
   FALSE 	TRUE
0 	1069 	6
1 	187 	11
```{r}
sensitivity = 11 /(187+11)
sensitivity
specificity = 1069/(1069+6)
specificity
```
# Recitation
```{r}
polling <- read.csv("PollingData.csv")
install.packages("mice",dependencies = T, repos="http://cran.rstudio.com/")
require(mice)
simple = polling[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount")]
summary(simple)
set.seed(144)
imputed = complete(mice(simple))
summary(imputed)
polling$Rasmussen <- imputed$Rasmussen
polling$SurveyUSA <- imputed$SurveyUSA
Train = subset(polling,Year == 2004 | Year == 2008)
Test = subset(polling,Year == 2012)
table(Train$Republican)
#smart baseline model 
table(sign(Train$Rasmussen))
table(Train$Republican,sign(Train$Rasmussen))
#regression model 
cor(Train[c("Rasmussen","SurveyUSA","PropR","DiffCount","Republican")])
# "PropR" is most correlated with the "Repulican"
mod1 <- glm(Republican~PropR,data = Train, family = "binomial")
summary(mod1)
pred1 = predict(mod1,type = "response")
table(Train$Republican,pred1 >= 0.5)
# above model makes 4 mistakes (similar to the base model), try out surveyUSA and DiffCount which have small correlation 
mod2 <- glm(Republican~SurveyUSA+DiffCount,data = Train, family = "binomial")
summary(mod2)
table(Test$Republican,sign(Test$Rasmussen))
TestPrediction= predict(mod2,newdata = Test,type = "response")
table(Test$Republican,TestPrediction >=0.5)
# try another pair of independent variables Rasmussen and DiffCount 
mod3 <- glm(Republican~Rasmussen+DiffCount,data = Train,family = "binomial")
summary(mod3)
TestPrediction3  = predict(mod3,newdata = Test,type = "response")
table(Test$Republican,TestPrediction3>=0.5)
# model 3 produces exactly the same result as model 2 with a much smaller AIC (?)
```
# Assignment 3 
## Popularity of music records
The music industry has a well-developed market with a global annual revenue around $15 billion. The recording industry is highly competitive and is dominated by three big production companies which make up nearly 82% of the total annual album sales. 

Taking an analytics approach, we aim to use information about a song's properties to predict its popularity. The dataset songs.csv consists of all songs which made it to the Top 10 of the Billboard Hot 100 Chart from 1990-2010 plus a sample of additional songs that didn't make the Top 10. This data comes from three sources: Wikipedia, Billboard.com, and EchoNest.

### Problem 1 - Understanding the Data
```{r}
songs <- read.csv("songs.csv")
str(songs)
#How many observations (songs) are from the year 2010?
table(songs$year == 2010)
#How many songs does the dataset include for which the artist name is "Michael Jackson"?
table(songs$artistname == "Michael Jackson")
#Which of these songs by Michael Jackson made it to the Top 10? 
songs[which(songs$artistname == "Michael Jackson"& songs$Top10==1),]$songtitle
#The variable corresponding to the estimated time signature (timesignature) is discrete, meaning that it only takes integer values (0, 1, 2, 3, . . . ). What are the values of this variable that occur in our dataset? Which timesignature value is the most frequent among songs in our dataset?
table(songs$timesignature)
#Out of all of the songs in our dataset, the song with the highest tempo is one of the following songs. Which one is it?
songs[which.max(songs$tempo),]$songtitle
```
### Problem 2 - Creating Our Prediction Model
first use the subset function to split the data into a training set "SongsTrain" consisting of all the observations up to and including 2009 song releases, and a testing set "SongsTest", consisting of the 2010 song releases.
```{r}
songsTrain <- subset(songs,year <=2009)
songsTest <- subset(songs,year ==2010)
nonvars <-c("year","songtitle","artistname","songID","artistID")
songsTrain = songsTrain[,!(names(songsTrain) %in% nonvars)]
songsTest = songsTest[,!(names(songsTest) %in% nonvars)]
songs.glm1 <- glm(Top10~., data = songsTrain, family = binomial)
summary(songs.glm1)
```
###Problem 3 - Beware of Multicollinearity Issues!
```{r}
cor(songs$loudness,songs$energy)
songs.glm2 <- glm(Top10~.-loudness,data= songsTrain,family = binomial)
summary(songs.glm2)
songs.glm3<- glm(Top10~.-energy,data = songsTrain,family = binomial)
summary(songs.glm3)
```
### Problem 4 - Validating Our Model
```{r}
songsPred <- predict(songs.glm3,newdata = songsTest,type = "response")
table(songsTest$Top10,songsPred>=0.45)
accuracy = (309+19)/(309+5+40+19)
accuracy
# What would the accuracy of the baseline model be on the test set?  
table(songsTest$Top10)
accuracy.base = 314/(314+59)
accuracy.base
#What is the sensitivity/specificity of Model 3 on the test set, using a threshold of 0.45?
sensitivity = 19/(19+40)
specificity = 309/(309+5) 
sensitivity
specificity
```
## Predicting parole violators
In this problem, we will build and validate a model that predicts if an inmate will violate the terms of his or her parole. Such a model could be useful to a parole board when deciding to approve or deny an application for parole.

For this prediction task, we will use data from the United States 2004 National Corrections Reporting Program, a nationwide census of parole releases that occurred during 2004. We limited our focus to parolees who served no more than 6 months in prison and whose maximum sentence for all charges did not exceed 18 months. The dataset contains all such parolees who either successfully completed their term of parole during 2004 or those who violated the terms of their parole during that year. The dataset contains the following variables:
```{r}
parole<-read.csv("parole.csv")
str(parole)
table(parole$violator)
summary(parole)
parole$state<-as.factor(parole$state)
parole$crime<-as.factor(parole$crime)
summary(parole)
set.seed(144)
library(caTools)
split = sample.split(parole$violator,SplitRatio = 0.7)
parolTrain = subset(parole,split ==TRUE)
parolTest = subset(parole,split == FALSE)
parol.glm1<-glm(violator~.,data = parolTrain,family=binomial)
summary(parol.glm1)
# Consider a parolee who is male, of white race, aged 50 years at prison release, from the state of Maryland, served 3 months, had a maximum sentence of 12 months, did not commit multiple offenses, and committed a larceny. 
#According to the model, what are the odds this individual is a violator? (8 independent variables + intercept)
b0 = coef(parol.glm1)[1]; b1=coef(parol.glm1)[2]; b2 = coef(parol.glm1)[3]; b3 = coef(parol.glm1)[4] ; b4 = 0.0 #for reference state
b5 = coef(parol.glm1)[8]; b6 = coef(parol.glm1)[9]; b7 = coef(parol.glm1)[10]; b8 = coef(parol.glm1)[11]
logit <- function(x1,x2,x3,x4,x5,x6,x7,x8) {return(b0 + b1*x1 + b2 * x2 + b3 * x3 +  b4 * x4 + b5 * x5 + b6 * x6 + b7 * x7 + b8 * x8)}
z = logit(1,1,50,1,3,12,0,1)
odds <- exp(z)
odds
#According to the model, what is the probability this individual is a violator?
p <- 1/(1+exp(-1*z)) 
p
# evaluating the model 
parol.prediction1 <- predict(parol.glm1,newdata = parolTest,type = "response")
summary(parol.prediction1)
table(parolTest$violator,parol.prediction1>=0.5)
sensitivity  = 12/(12+11)
sensitivity 
specificity = 167/(167+12)
specificity 
accuracy = (167+12)/(167+12+11+12)
accuracy
# What is the accuracy of a simple model that predicts that every parolee is a non-violator? 
table(parolTest$violator)
(179)/(179+23)
table(parolTest$violator,parol.prediction1>=0.45) # using a cutoff < 0.5 reduces the false negative (from 11 to 10) which is more important 
#install.packages("ROCR")
require(ROCR)
ROCprediction <- prediction(parol.prediction1, parolTest$violator)
auc = as.numeric(performance(ROCprediction,"auc")@y.values)
auc
```
## Predicting loan repayment
In the lending industry, investors provide loans to borrowers in exchange for the promise of repayment with interest. If the borrower repays the loan, then the lender profits from the interest. However, if the borrower is unable to repay the loan, then the lender loses money. Therefore, lenders face the problem of predicting the risk of a borrower being unable to repay a loan.To address this problem, we will use publicly available data from LendingClub.com, a website that connects borrowers and investors over the Internet. This dataset represents 9,578 3-year loans that were funded through the LendingClub.com platform between May 2007 and February 2010. 

```{r}
loans<-read.csv("loans.csv")
str(loans)
summary(loans)
prop.table(table(loans$not.fully.paid))

#Which of the following is the best reason to fill in the missing values for these variables instead of removing observations with missing data?
table(complete.cases(loans))
# subset with at least one NA
NArows<-subset(loans, !complete.cases(loans))
nrow(NArows)
prop.table(table(NArows$not.fully.paid))

# preparing the dataset with multiple imputation 
library(mice)
set.seed(144)
vars.for.imputation = setdiff(names(loans),"not.fully.paid")
imputed <- complete(mice(loans[vars.for.imputation]))
loans[vars.for.imputation] = imputed
```
### Problem 2.1 - prediction models 
```{r}
set.seed(144)
loansSplit <- sample.split(loans$not.fully.paid,SplitRatio = 0.7)
loansTrain <- subset(loans, loansSplit ==TRUE)
loansTest <- subset(loans, loansSplit ==FALSE)
nrow(loansTrain)/nrow(loans)
loans.glm <- glm(not.fully.paid~.,data = loansTrain,family =binomial) 
summary(loans.glm)
```
### Problem 2.2 - Prediction Models
Consider two loan applications, which are identical other than the fact that the borrower in Application A has FICO credit score 700 while the borrower in Application B has FICO credit score 710.

Let Logit(A) be the log odds of loan A not being paid back in full, according to our logistic regression model, and define Logit(B) similarly for loan B. What is the value of Logit(A) - Logit(B)?
```{r}
-9.406e-03 * (700 - 710)
```
Now, let O(A) be the odds of loan A not being paid back in full, according to our logistic regression model, and define O(B) similarly for loan B. What is the value of O(A)/O(B)?
```{r}
exp(-9.406e-03 * (700 - 710))
```
### Problem 2.3 - Prediction Models
Predict the probability of the test set loans not being paid back in full (remember type="response" for the predict function). 
```{r}
loansTest$predicted.risk  <- predict(loans.glm,newdata =loansTest,type = "response")
table(loansTest$not.fully.paid,loansTest$predicted.risk>=0.5)
accuracy <- (2400+3)/(2400+3+457+3)
accuracy
# What is the accuracy of the baseline model? 
table(loansTest$not.fully.paid)
accuracy.base <- 2413/(2413+460)
accuracy.base 
#Use the ROCR package to compute the test set AUC.
require(ROCR)
ROCRloansTest <- prediction(loansTest$predicted.risk,loansTest$not.fully.paid)
auc = as.numeric(performance(ROCRloansTest,"auc")@y.values)
auc
```
### Problem 3.1 - A "Smart Baseline"
In this part, we will investigate using the loan's interest rate as a "smart baseline" to order the loans according to risk.
Make test set predictions for the bivariate model. What is the highest predicted probability of a loan not being paid in full on the testing set?
```{r}
bivariate.glm <- glm(not.fully.paid~int.rate,data = loansTrain,family = binomial)
summary(bivariate.glm)
bivariate.risk<-predict(bivariate.glm,newdata = loansTest,type = "response")
summary(bivariate.risk)
ROCbivariate <- prediction(bivariate.risk,loansTest$not.fully.paid)
auc.bi <- as.numeric(performance(ROCbivariate,"auc")@y.values)
auc.bi
```
### Problem 4.1 - Computing the Profitability of an Investment 
```{r}
payback = function(inves,interest, t){return(inves*exp(interest * t))}
payback(10.0,0.06,3)
```
### Problem 5 - A Simple Investment Strategy
```{r} 
loansTest$profit <- exp(loansTest$int.rate*3) - 1 
loansTest$profit[loansTest$not.fully.paid ==1] = -1
summary(loansTest$profit)
# What is the maximum profit of a $10 investment in any loan in the testing set
10.0*max(loansTest$profit)
```
### Problem 6 - An Investment Strategy Based on Risk
```{r}
loans.highint<-subset(loansTest,loansTest$int.rate >=0.15)
nrow(loans.highint)
#What is the average profit of a $1 investment in one of these high-interest loans
mean(loans.highint$profit)
#What proportion of the high-interest loans were not paid back in full?
prop.table(table(loans.highint$not.fully.paid))
# Next, we will determine the 100th smallest predicted probability of not paying in full by sorting the predicted risks in increasing order and selecting the 100th element of this sorted list. Find the highest predicted risk that we will include
cutoff = sort(loans.highint$predicted.risk, decreasing=FALSE)[100]
selectedLoans <- subset(loans.highint,loans.highint$predicted.risk <= cutoff)
nrow(selectedLoans)
sum(selectedLoans$profit)
table(selectedLoans$not.fully.paid)
```
### Redo Problem 6 using loans_imputed.csv"
```{r}
loansImputed<-read.csv("loans_imputed.csv")
table(complete.cases(loansImputed))
set.seed(144)
loansImputedSplit <- sample.split(loansImputed$not.fully.paid,SplitRatio = 0.7)
loansImputedTrain <- subset(loansImputed, loansSplit ==TRUE)
loansImputedTest <- subset(loansImputed, loansSplit ==FALSE)
loansImputed.glm <- glm(not.fully.paid~.,data = loansImputedTrain,family =binomial) 
loansImputedTest$predicted.risk  <- predict(loansImputed.glm,newdata =loansImputedTest,type = "response")
table(loansImputedTest$not.fully.paid,loansImputedTest$predicted.risk >=0.5)
#
loansImputedTest$profit <- exp(loansImputedTest$int.rate*3) - 1 
loansImputedTest$profit[loansImputedTest$not.fully.paid ==1] = -1
summary(loansImputedTest$profit)
#
loansImputed.highint<-subset(loansImputedTest,loansImputedTest$int.rate >=0.15)
nrow(loansImputed.highint)
# Next, we will determine the 100th smallest predicted probability of not paying in full by sorting the predicted risks in increasing order and selecting the 100th element of this sorted list. Find the highest predicted risk that we will include
cutoff = sort(loansImputed.highint$predicted.risk, decreasing=FALSE)[100]
selectedLoans <- subset(loansImputed.highint,loansImputed.highint$predicted.risk <= cutoff)
nrow(selectedLoans)
sum(selectedLoans$profit)
table(selectedLoans$not.fully.paid)
```