---
title: "The Analytics Edge (Unit 5)"
author: "Na Sai"
date: "April 10, 2015"
output: html_document
---
# Assignment 5 
## 5.1 Detecting vandalism on wikipedia  
One of the consequences of being editable by anyone is that some people vandalize pages. This can take the form of removing content, adding promotional or inappropriate content, or more subtle shifts that change the meaning of the article. With this many articles and edits per day it is difficult for humans to detect all instances of vandalism and revert (undo) them. As a result, Wikipedia uses bots - computer programs that automatically revert edits that look like vandalism. In this assignment we will attempt to develop a vandalism detector that uses machine learning to distinguish between a valid edit and vandalism.

The data for this problem is based on the revision history of the page Language. Wikipedia provides a history for each page that consists of the state of the page at each revision. Rather than manually considering each revision, a script was run that checked whether edits stayed or were reverted. If a change was eventually reverted then that revision is marked as vandalism. This may result in some misclassifications, but the script performs well enough for our needs.

```{r}
wiki <- read.csv("wiki.csv",stringsAsFactors=FALSE)
str(wiki)
wiki$Vandal = as.factor(wiki$Vandal)
table(wiki$Vandal)

library(tm)
# the added terms
vs <- VectorSource(wiki$Added)
corpusAdded<-Corpus(vs)
#inspect(corpusAdded)
# already in lowercase and stripped of punctuation
# check if length(stopwords("english")) returns 174 l
corpusAdded <- tm_map(corpusAdded,removeWords,stopwords("english"))
corpusAdded <- tm_map(corpusAdded, stemDocument)  
# build the DocumentTermMatrix 
corpusAdded[[1]]
# build matrix 
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded
# remove words that appear not more than 0.03% 
sparseAdded <- removeSparseTerms(dtmAdded, 0.997)
sparseAdded
# convert to a data frame 
wordsAdded <- as.data.frame(as.matrix(sparseAdded)) 
# prepend all the words with the letter A
colnames(wordsAdded) = paste("A",colnames(wordsAdded))

# repeat the above steps to create a Removed bag-of-words dataframe
vs <- VectorSource(wiki$Removed)
corpusRemoved<-Corpus(vs)
corpusRemoved<-tm_map(corpusRemoved,removeWords,stopwords("english"))
corpusRemoved<-tm_map(corpusRemoved,stemDocument)
dtmRemoved<-DocumentTermMatrix(corpusRemoved)
dtmRemoved
sparseRemoved<-removeSparseTerms(dtmRemoved,0.997)
sparseRemoved
wordsRemoved<- as.data.frame(as.matrix(sparseRemoved))
colnames(wordsRemoved) <-paste("R",colnames(wordsRemoved))
wikiWords<-cbind(wordsAdded,wordsRemoved)
wikiWords$Vandal <- wiki$Vandal
set.seed(123)

library(caTools)
spl <- sample.split(wikiWords$Vandal,SplitRatio = 0.7) 

wikiTrain <- subset(wikiWords,spl==TRUE)
wikiTest<-subset(wikiWords,spl == FALSE)
table(wikiTest$Vandal)
acc.base <-618 / (618 + 545) 
acc.base

# cart model 
library(rpart)
library(rpart.plot)
wikiRpart<- rpart(Vandal~., data  = wikiTrain,method="class")
prp(wikiRpart)
wikiRpart.pred <-predict(wikiRpart, newdata = wikiTest,type = "class")
tbl<-table(wikiTest$Vandal,wikiRpart.pred)
acc.rpart<- sum(diag(tbl))/sum(tbl)
acc.rpart

# try two techniques- identifying a key class of words, and counting words
wikiWords2 <- wikiWords
wikiWords2$HTTP <- ifelse(grepl("http",wiki$Added,fixed=TRUE),1,0)
table(wikiWords2$HTTP)
wikiTrain2a<-subset(wikiWords2,spl==TRUE)
wikiTest2a<-subset(wikiWords2,spl==FALSE)
wikiRpart2a<- rpart(Vandal~.,data = wikiTrain2a,method = "class")
prp(wikiRpart2a)
wikiRpart2a.pred<-predict(wikiRpart2a,newdata = wikiTest2a,type = "class")
tbl<-table(wikiTest2a$Vandal,wikiRpart2a.pred)
acc.rpart2a<- sum(diag(tbl))/sum(tbl)
acc.rpart2a

# counting the words 
wikiWords2$NumWordsAdded<-rowSums(as.matrix(dtmAdded))
wikiWords2$NumWordsRemoved<-rowSums(as.matrix(dtmRemoved))
summary(wikiWords2$NumWordsAdded)

wikiTrain2b<-subset(wikiWords2,spl==TRUE)
wikiTest2b<-subset(wikiWords2,spl==FALSE)
wikiRpart2b<- rpart(Vandal~.,data = wikiTrain2b,method = "class")
prp(wikiRpart2b)
wikiRpart2b.pred<-predict(wikiRpart2b,newdata = wikiTest2b,type = "class")
tbl<-table(wikiTest2b$Vandal,wikiRpart2b.pred)
acc.rpart2b<- sum(diag(tbl))/sum(tbl)
acc.rpart2b

# add two pieces of "metadata" (data about data) we haven't yet used. 
wikiWords3 = wikiWords2
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin

wikiTrain3<-subset(wikiWords3,spl==TRUE)
wikiTest3<-subset(wikiWords3,spl==FALSE)
wikiRpart3<- rpart(Vandal~.,data = wikiTrain3,method = "class")
prp(wikiRpart3)
wikiRpart3.pred<-predict(wikiRpart3,newdata = wikiTest3,type = "class")
tbl<-table(wikiTest3$Vandal,wikiRpart3.pred)
acc.rpart3<- sum(diag(tbl))/sum(tbl)
acc.rpart3
```

## 5.2 automating reviews in medicine
The medical literature is enormous. Pubmed, a database of medical publications maintained by the U.S. National Library of Medicine, has indexed over 23 million medical publications. Further, the rate of medical publication has increased over time, and now there are nearly 1 million new publications in the field each year, or more than one per minute.

The large size and fast-changing nature of the medical literature has increased the need for reviews, which search databases like Pubmed for papers on a particular topic and then report results from the papers found. While such reviews are often performed manually, with multiple people reviewing each search result, this is tedious and time consuming. In this problem, we will see how text analytics can be used to automate the process of information retrieval.

The dataset consists of the titles (variable title) and abstracts (variable abstract) of papers retrieved in a Pubmed search. Each search result is labeled with whether the paper is a clinical trial testing a drug therapy for cancer (variable trial). These labels were obtained by two people reviewing each search result and accessing the actual paper if necessary, as part of a literature review of clinical trials testing drug therapies for advanced and metastatic breast cancer.
```{r}
trials<-read.csv("clinical_trial.csv",stringsAsFactors = FALSE)
str(trials)
summary(trials)
#How many characters are there in the longest abstract?
summary(nchar(trials$abstract))
#How many search results provided no abstract? 
table(nchar(trials$abstract) == 0)
#Find the observation with the minimum number of characters in the title. What is the text of the title of this article? 
which.min(nchar(trials$title))
trials$title[1258]

library(tm)
vs<-VectorSource(trials$title)
corpusTitle<-Corpus(vs)
corpusTitle<-tm_map(corpusTitle,tolower)
corpusTitle <-tm_map(corpusTitle,PlainTextDocument)
corpusTitle <- tm_map(corpusTitle,removePunctuation)
corpusTitle <- tm_map(corpusTitle,removeWords,stopwords("english"))
corpusTitle <- tm_map(corpusTitle,stemDocument)
dtmTitle <- DocumentTermMatrix(corpusTitle)
dtmTitle <- removeSparseTerms(dtmTitle,0.95)
dtmTitle

vs<-VectorSource(trials$abstract)
corpusAbstract<-Corpus(vs)
corpusAbstract<-tm_map(corpusAbstract,tolower)
corpusAbstract <-tm_map(corpusAbstract,PlainTextDocument)
corpusAbstract <- tm_map(corpusAbstract,removePunctuation)
corpusAbstract <- tm_map(corpusAbstract,removeWords,stopwords("english"))
corpusAbstract <- tm_map(corpusAbstract,stemDocument)
dtmAbstract <- DocumentTermMatrix(corpusAbstract)
dtmAbstract <- removeSparseTerms(dtmAbstract,0.95)
dtmAbstract

# What is the most frequent word stem across all the abstracts?
which.max(colSums(as.matrix(dtmAbstract)))


#typeof(dtmAbstract)
dtmTitle <- as.data.frame(as.matrix(dtmTitle))
dtmAbstract <- as.data.frame(as.matrix(dtmAbstract))
colnames(dtmTitle)<-paste0("T",colnames(dtmTitle))
colnames(dtmAbstract)<-paste0("A",colnames(dtmAbstract))
dtm <- cbind(dtmTitle,dtmAbstract)
dtm$trial <- trials$trial
ncol(dtm)

# split data 
library(caTools)
set.seed(144)
spl <- sample.split(dtm$trial,SplitRatio = 0.7)
dtmTrain <- subset(dtm,spl == TRUE)
dtmTest <- subset(dtm,spl == FALSE)
# base line model on training set
table(dtm$trial)
1043/(1043+817)

# cart model 
library(rpart)
library(rpart.plot)
dtmRpart <- rpart(trial~.,data = dtmTrain, method = "class") 
prp(dtmRpart)
#Obtain the training set predictions for the model. What is the maximum predicted probability for any result?
max(predict(dtmRpart,newdata = dtmTrain)[,2])
# evaluate accuracy on the training set 
dtmRpart.pred <- predict(dtmRpart,newdata = dtmTrain, type = "class")
tbl<- table(dtmTrain$trial,dtmRpart.pred)                                  
sum(diag(tbl))/sum(tbl)
tbl
# sensitivity  = TP/TP + FN
441/(441+131)
# specificity = TN/TN + FP   
631/(631+99)


# evaluate accuracy on the test set 
dtmRpart.pred <- predict(dtmRpart,newdata = dtmTest,type = "class")
tbl<- table(dtmTest$trial,dtmRpart.pred)                                  
sum(diag(tbl))/sum(tbl)
max(predict(dtmRpart,newdata = dtmTest)[,2])
# roc
library(ROCR)
dtmRpart.pred <- predict(dtmRpart,newdata = dtmTest)
dtm.roc<- prediction(dtmRpart.pred[,2],dtmTest$trial)
auc<-as.numeric(performance(dtm.roc,"auc")@y.values)
auc
```
## 5.3 separating spam from ham (Part 1)
Nearly every email user has at some point encountered a "spam" email, which is an unsolicited message often advertising a product, containing links to malware, or attempting to scam the recipient. Roughly 80-90% of more than 100 billion emails sent each day are spam emails, most being sent from botnets of malware-infected computers. The remainder of emails are called "ham" emails.

As a result of the huge number of spam emails being sent across the Internet each day, most email providers offer a spam filter that automatically flags likely spam messages and separates them from the ham. Though these filters use a number of techniques (e.g. looking up the sender in a so-called "Blackhole List" that contains IP addresses of likely spammers), most rely heavily on the analysis of the contents of an email via text analytics.

In this homework problem, we will build and evaluate a spam filter using a publicly available dataset first described in the 2006 conference paper "Spam Filtering with Naive Bayes -- Which Naive Bayes?" by V. Metsis, I. Androutsopoulos, and G. Paliouras. The "ham" messages in this dataset come from the inbox of former Enron Managing Director for Research Vincent Kaminski, one of the inboxes in the Enron Corpus. One source of spam messages in this dataset is the SpamAssassin corpus, which contains hand-labeled spam messages contributed by Internet users. The remaining spam was collected by Project Honey Pot, a project that collects spam messages and identifies spammers by publishing email address that humans would know not to contact but that bots might target with spam. The full dataset we will use was constructed as roughly a 75/25 mix of the ham and spam messages.
```{r}
emails <- read.csv("emails.csv",stringsAsFactors=FALSE)
str(emails)
#How many of the emails are spam?
table(emails$spam)
#How many characters are in the longest email in the dataset 
summary(nchar(emails$text))
#Which row contains the shortest email in the dataset?
which.min(nchar(emails$text))

# build the corpus 
vs<- VectorSource(emails$text)
corpus <- Corpus(vs)
corpus<- tm_map(corpus,tolower)
corpus <- tm_map(corpus, PlainTextDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus,removeWords,stopwords("english"))
corpus <- tm_map(corpus,stemDocument)

# build matrix 
dtm<- DocumentTermMatrix(corpus)
dtm
spdtm <-removeSparseTerms(dtm,0.95)
spdtm

#build dataframe
emailsSparse<- as.data.frame(as.matrix(spdtm))
colnames(emailsSparse)<- make.names(colnames(emailsSparse))

#  What is the word stem that shows up most frequently across all the emails in the dataset?
which.max(colSums(emailsSparse))

# Add a variable called "spam" to emailsSparse containing the email spam labels.
emailsSparse$spam <- emails$spam

# How many word stems appear at least 5000 times in the ham emails in the dataset? 
which(colSums(subset(emailsSparse,spam==0))>=5000)  

# How many word stems appear at least 1000 times in the spam emails in the dataset? remember not to count the dependent variable we just added.
which(colSums(subset(emailsSparse,spam==1))>=1000)  

#convert the dependent variable to a factor 
emailsSparse$spam <- as.factor(emailsSparse$spam)

# split data 
set.seed(123)
library(caTools)
spl <- sample.split(emailsSparse$spam,SplitRatio = 0.7)
train <- subset(emailsSparse,spl==TRUE)
test<- subset(emailsSparse,spl==FALSE)
```

### logistic model 
```{r}
spamLog <- glm(spam~.,data = train, family = "binomial")
log.pred<-predict(spamLog,newdata = train,type = "response")

# How many of the training set predicted probabilities from spamLog are less than 0.00001?
table(log.pred< 0.00001)

#How many of the training set predicted probabilities from spamLog are more than 0.99999
table(log.pred>0.99999)

#How many of the training set predicted probabilities from spamLog are between 0.00001 and 0.99999?
table(log.pred<=0.99999 & log.pred>=0.00001)

#How many variables are labeled as significant (at the p=0.05 level) in the logistic regression summary output?
any(coef(summary(spamLog))[,4]<0.95)

# What is the training set accuracy of spamLog, using a threshold of 0.5 for predictions?
tbl <- table(train$spam, log.pred >=0.5)
sum(diag(tbl))/sum(tbl)

# What is the training set AUC of spamLog?
logRoc.pred<- prediction(log.pred, train$spam)
auc<-as.numeric(performance(logRoc.pred,"auc")@y.values)
auc
# What is the testing set accuracy of spamLog, using a threshold of 0.5 for predictions?
logTest.pred<-predict(spamLog,newdata = test,type = "response")
tbl <- table(test$spam, logTest.pred >=0.5)
sum(diag(tbl))/sum(tbl)
# What is the testing set AUC of spamLog?
logRocTest.pred<- prediction(logTest.pred, test$spam)
auc<-as.numeric(performance(logRocTest.pred,"auc")@y.values)
auc
```

### cart model 
```{r}
library(rpart)
library(rpart.plot)
spamCart <- rpart(spam~.,data = train)
prp(spamCart)
#What is the training set accuracy of spamCART, using a threshold of 0.5 for predictions?
cart.pred<-predict(spamCart,newdata = train)
tbl<-table(train$spam,cart.pred[,2]>=0.5)
sum(diag(tbl))/sum(tbl)
# What is the training set AUC of spamCART?
cartRoc.pred<- prediction(cart.pred[,2], train$spam)
auc<-as.numeric(performance(cartRoc.pred,"auc")@y.values)
auc

# What is the testing set accuracy of spamCART, using a threshold of 0.5 for predictions?
cartTest.pred<-predict(spamCart,newdata = test)
tbl<-table(test$spam,cartTest.pred[,2]>=0.5)
sum(diag(tbl))/sum(tbl)
# What is the testing set AUC of spamCART?
cartRocTest.pred<- prediction(cartTest.pred[,2], test$spam)
auc<-as.numeric(performance(cartRocTest.pred,"auc")@y.values)
auc
```

### random forest model
```{r}
library(randomForest)
set.seed(123)
spamRF <- randomForest(spam~.,data = train)
# What is the training set accuracy of spamRF
rf.pred<-predict(spamRF,newdata = train,type="prob")
tbl<-table(train$spam,rf.pred[,2]>=0.5)
sum(diag(tbl))/sum(tbl)
# What is the training set AUC of spamRF? 
rfRoc.pred<- prediction(rf.pred[,2], train$spam)
auc<-as.numeric(performance(rfRoc.pred,"auc")@y.values)
auc
# What is the testing set accuracy of spamRF, using a threshold of 0.5 for predictions?
rfTest.pred<-predict(spamRF,newdata = test,type="prob")
tbl<-table(test$spam,rfTest.pred[,2]>=0.5)
sum(diag(tbl))/sum(tbl)
# What is the testing set AUC of spamRF?
rfRocTest.pred<- prediction(rfTest.pred[,2], test$spam)
auc<-as.numeric(performance(rfRocTest.pred,"auc")@y.values)
auc  
```
## 5.4 Separating Spam from Ham (Part 2 - OPTIONAL)
```{r}
wordCount = rowSums(as.matrix(dtm))
# if running out of memory
#library(slam)
#wordCount = rollup(dtm, 2, FUN=sum)$v 
hist(wordCount)
hist(log(wordCount))

emailsSparse$logWordCount <- log(wordCount)
boxplot(logWordCount~spam,data = emailsSparse, main = "Log(WordCount) by spam",ylab = "log(WordCount)", xlab="spam")

#Because logWordCount differs between spam and ham messages, we hypothesize that it might be useful in predicting whether an email is spam. 

train2 <- subset(emailsSparse,spl==TRUE)
test2 <- subset(emailsSparse,spl==FALSE)

# cart model 

spam2Cart <- rpart(spam~., data = train2, method = "class")
prp(spam2Cart)
cart2Test.pred<-predict(spam2Cart,newdata = test2)
tbl<-table(test2$spam,cart2Test.pred[,2]>=0.5)
sum(diag(tbl))/sum(tbl)

cart2RocTest.pred<- prediction(cart2Test.pred[,2], test2$spam)
auc<-as.numeric(performance(cart2RocTest.pred,"auc")@y.values)
auc

# rF model 
set.seed(123)
spam2RF <- randomForest(spam~.,data = train2)

rf2Test.pred<-predict(spam2RF,newdata = test2,type="prob")
tbl<-table(test2$spam,rf2Test.pred[,2]>=0.5)
sum(diag(tbl))/sum(tbl)
# What is the testing set AUC of spamRF?
rf2RocTest.pred<- prediction(rf2Test.pred[,2], test2$spam)
auc<-as.numeric(performance(rf2RocTest.pred,"auc")@y.values)
auc  
```

## 5.5 Using n-grams

Another source of information that might be extracted from text is the frequency of various n-grams. An n-gram is a sequence of n consecutive words in the document. For instance, for the document "Text analytics rocks!", which we would preprocess to "text analyt rock", the 1-grams are "text", "analyt", and "rock", the 2-grams are "text analyt" and "analyt rock", and the only 3-gram is "text analyt rock". n-grams are order-specific, meaning the 2-grams "text analyt" and "analyt text" are considered two separate n-grams. We can see that so far our analysis has been extracting only 1-grams.

We do not have exercises in this class covering n-grams, but if you are interested in learning more, the "RTextTools", "tau", "RWeka", and "textcat" packages in R are all good resources.


