{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww12060\viewh12300\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 ---\
title: "The Analytics Edge (Unit 6)"\
author: "Na Sai"\
date: "April 20, 2015"\
output: html_document\
---\
\
# Quick Question \
## Computing Distances\
The movie "The Godfather" is in the genres action, crime, and drama, and is defined by the vector: (0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0)\
\
The movie "Titanic" is in the genres action, drama, and romance, and is defined by the vector: (0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0)\
\
What is the distance between "The Godfather" and "Titanic", using euclidean distance?\
\
```\{r\}\
x1 <- c(0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0)\
x2 <- c(0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0)\
EucDis <- sqrt(sum((x2-x1)^2))\
EucDis\
```\
## Movies Data \
In this video, we'll be downloading our dataset from the MovieLens website. Please open the following link in a new window or tab of your browser to access the data: http://files.grouplens.org/datasets/movielens/ml-100k/u.item\
\
```\{r\}\
# After following the steps in the video, load the data into R\
movies = read.table("movieLens.txt", header=FALSE, sep="|",quote="\\"")\
\
str(movies)\
\
# Add column names\
colnames(movies) = c("ID", "Title", "ReleaseDate", "VideoReleaseDate", "IMDB", "Unknown", "Action", "Adventure", "Animation", "Childrens", "Comedy", "Crime", "Documentary", "Drama", "Fantasy", "FilmNoir", "Horror", "Musical", "Mystery", "Romance", "SciFi", "Thriller", "War", "Western")\
\
str(movies)\
\
# Remove unnecessary variables\
movies$ID = NULL\
movies$ReleaseDate = NULL\
movies$VideoReleaseDate = NULL\
movies$IMDB = NULL\
\
# Remove duplicates\
movies = unique(movies)\
\
# Take a look at our data again:\
str(movies)\
\
\
# How many movies are classified as comedies?\
table(movies$Comedy)\
table(movies$Western)\
table(movies$Drama==1&movies$Romance==1)\
\
\
# Compute distances\
distances = dist(movies[2:20], method = "euclidean")\
\
# Hierarchical clustering\
clusterMovies = hclust(distances, method = "ward.D")\
#clusterMovies = hclust(distances, method = "ward") \
\
# Plot the dendrogram\
plot(clusterMovies)\
\
# Assign points to clusters\
clusterGroups = cutree(clusterMovies, k = 2)\
tapply(movies$Action, clusterGroups, mean)\
tapply(movies$Comedy, clusterGroups, mean)\
tapply(movies$Adventure, clusterGroups, mean)\
tapply(movies$Romance, clusterGroups, mean)\
tapply(movies$Drama, clusterGroups, mean)\
```\
\
# Assignment 6 \
## 6.1 \
document clustering with daily kos\
\
Document clustering, or text clustering, is a very popular application of clustering algorithms. A web search engine, like Google, often returns thousands of results for a simple query. For example, if you type the search term "jaguar" into Google, around 200 million results are returned. This makes it very difficult to browse or find relevant information, especially if the search term has multiple meanings. If we search for "jaguar", we might be looking for information about the animal, the car, or the Jacksonville Jaguars football team. \
\
Clustering methods can be used to automatically group search results into categories, making it easier to find relavent results. This method is used in the search engines PolyMeta and Helioid, as well as on FirstGov.gov, the official Web portal for the U.S. government. The two most common algorithms used for document clustering are Hierarchical and k-means. \
\
In this problem, we'll be clustering articles published on Daily Kos, an American political blog that publishes news and opinion articles written from a progressive point of view. Daily Kos was founded by Markos Moulitsas in 2002, and as of September 2014, the site had an average weekday traffic of hundreds of thousands of visits. \
```\{r\}\
kos<-read.csv("dailykos.csv")\
str(kos)\
\
# distance \
kos.dist = dist(kos, method = "euclidean") \
\
kosClusters<-hclust(kos.dist, method="ward.D")\
\
# Select 7 clusters\
\
kosClusters = cutree(kosClusters, k = 7)\
kosClusters\
\
\
\
#Create 7 new datasets, each containing the observations from one of the clusters.\
#How many observations are in cluster 3?\
cluster1 = subset(kos, kosClusters==1)\
cluster2 = subset(kos, kosClusters==2)\
cluster3 = subset(kos, kosClusters==3)\
cluster4 = subset(kos, kosClusters==4)\
cluster5 = subset(kos, kosClusters==5)\
cluster6 = subset(kos, kosClusters==6)\
cluster7 = subset(kos, kosClusters==7)\
\
nrow(cluster1)\
nrow(cluster2)\
nrow(cluster3)\
nrow(cluster4)\
nrow(cluster5)\
nrow(cluster6)\
nrow(cluster7)\
\
tail(sort(colMeans(cluster1)))\
tail(sort(colMeans(cluster2)))\
tail(sort(colMeans(cluster3)))\
tail(sort(colMeans(cluster4)))\
tail(sort(colMeans(cluster5)))\
tail(sort(colMeans(cluster6)))\
tail(sort(colMeans(cluster7)))\
\
tapply(flowerVector, flowerClusters, mean)\
\
#kmean\
k= 7 \
set.seed(1000)\
KMC = kmeans(kos, centers = k)\
# Extract clusters\
kosKMC = KMC$cluster\
#How many observations are in Cluster 3?\
table(kosKMC)\
\
#output the six most frequent words in each cluster,\
\
KMC1 = subset(kos, kosKMC==1)\
KMC2 = subset(kos, kosKMC==2)\
KMC3 = subset(kos, kosKMC==3)\
KMC4 = subset(kos, kosKMC==4)\
KMC5 = subset(kos, kosKMC==5)\
KMC6 = subset(kos, kosKMC==6)\
KMC7 = subset(kos, kosKMC==7)\
\
tail(sort(colMeans(KMC1)))\
tail(sort(colMeans(KMC2)))\
tail(sort(colMeans(KMC3)))\
tail(sort(colMeans(KMC4)))\
tail(sort(colMeans(KMC5)))\
tail(sort(colMeans(KMC6)))\
tail(sort(colMeans(KMC7)))\
\
\
# compare KMC and H cluster groups \
table(kosClusters,kosKMC)\
\
```\
\
## 6.2 \
market Segmentation For Airlines\
\
Market segmentation is a strategy that divides a broad target market of customers into smaller, more similar groups, and then designs a marketing strategy specifically for each group. Clustering is a common technique for market segmentation since it automatically finds similar groups given a data set. \
\
In this problem, we'll see how clustering can be used to find similar groups of customers who belong to an airline's frequent flyer program. The airline is trying to learn more about its customers so that it can target different customer segments with different types of mileage offers. \
\
The file AirlinesCluster.csv contains information on 3,999 members of the frequent flyer program. This data comes from the textbook "Data Mining for Business Intelligence," by Galit Shmueli, Nitin R. Patel, and Peter C. Bruce. For more information, see the website for the book.\
```\{r\}\
airlines<-read.csv("AirlinesCluster.csv")\
summary(airlines)\
str(airlines)\
library(caret)\
preproc = preProcess(airlines)\
airlinesNorm<- predict(preproc,airlines)\
summary(airlinesNorm)\
max(airlinesNorm)\
min(airlinesNorm)\
air.dis <- dist(airlines,method = "euclidean")\
\
airClusters<-hclust(air.dis, method="ward.D")\
plot(airClusters)\
\
airClusters = cutree(airClusters, k = 5)\
airCluster1 = subset(kos, airClusters==1)\
\
```\
\
\
\
\
\
\
\
\
\
airlines<-read.csv("AirlinesCluster.csv")\
summary(airlines)\
str(airlines)\
library(caret)\
preproc = preProcess(airlines)\
airlinesNorm<- predict(preproc,airlines)\
summary(airlinesNorm)\
max(airlinesNorm)\
min(airlinesNorm)\
air.dis <- dist(airlines,method = "euclidean")\
\
airClusters<-hclust(air.dis, method="ward.D")\
plot(airClusters)\
\
airClusters = cutree(airClusters, k = 5)\
airCluster1 = subset(kos, airClusters==1)}